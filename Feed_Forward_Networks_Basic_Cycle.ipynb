{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feed Forward Networks Basic Cycle.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj7gJx3yJcXv"
      },
      "source": [
        "!mkdir dataset\n",
        "!mkdir models\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0MF87bAJiQR"
      },
      "source": [
        "# Data study and problem study.\n",
        "\n",
        "In practice the recolection, anotation, and study of the data to use is a great amount of the work in the development of the model.\n",
        "\n",
        "We will start with a very simple dataset.\n",
        "\n",
        "## MNIST\n",
        "\n",
        "So basically we describe our task as follows:\n",
        "\n",
        "### Task\n",
        "\n",
        "Create a model capable of recongnice hand writed data.\n",
        "\n",
        "### Data\n",
        "\n",
        "[MNIST](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "Since this dataset has been for so long and it has been studied so much, we don't have to make all the necesary steps.\n",
        "\n",
        "1. Search for missing or incomplete examples.\n",
        "2. Look for ouliers.\n",
        "3. Study if relevant statistical hypothesis are fullfiled.\n",
        "4. Transform the examples to a data representation form adecuate for our model.\n",
        "5. Creating an efficient way to feed the data to the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVHjUPoXN1-U"
      },
      "source": [
        "\"\"\" All the work is going to be relativeley simple thanks to a well stablish\n",
        "tool for ML, DL, pytorch\n",
        "https://pytorch.org/\n",
        "\"\"\"\n",
        "\n",
        "## Used libraries ###\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "\n",
        "## ################ ##\n",
        "\n",
        "## MNIST DATA SET                                    ##\n",
        "## torch provides all the tools needed to user MNIS  ##\n",
        "## torch uses a special data structure called tensor ##\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), # change the data to tensor\n",
        "                                transforms.Normalize( # apply a transofr to get\n",
        "                                    (0.5,), # mean 0\n",
        "                                    (0.5,) # std 1, this has been proved to help.\n",
        "                                    )])\n",
        "\n",
        "train = datasets.MNIST('dataset/',\n",
        "                       download = True,\n",
        "                       train = True,\n",
        "                       transform = transform)\n",
        "\n",
        "val = datasets.MNIST('dataset/',\n",
        "                    download = True,\n",
        "                    train = False,\n",
        "                    transform=transform)\n",
        "\n",
        "## A mechanism to make the loading of the images to memory more effient. ##\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train,\n",
        "    batch_size = 256, # limited by the available memory\n",
        ")\n",
        "\n",
        "val_data_loader = torch.utils.data.DataLoader(\n",
        "    val,\n",
        "    batch_size = 256\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kh-ZLowPaES"
      },
      "source": [
        "\"\"\" To see what is in the dataset we can check some images. \"\"\"\n",
        "\n",
        "dataiter = iter(train_data_loader)\n",
        "x, t, = dataiter.next()\n",
        "\n",
        "print(f\"Shape of the tensor object: {x.shape}\")\n",
        "print(f\"Shape of the target vector: {t.shape}\")\n",
        "\n",
        "plt.imshow(x[0].numpy().squeeze(), cmap='gray')\n",
        "\n",
        "print(f\"Image Related to:{t[0]}\")\n",
        "print(f\"Flatten {torch.flatten(x, start_dim=1).shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXz6NqIgoB6v"
      },
      "source": [
        "# Model building\n",
        "\n",
        "## Model design.\n",
        "\n",
        "- This is an open question.\n",
        "- Best results, use popular architectures i.e. SOTA in related tasks.\n",
        "\n",
        "### FC\n",
        "\n",
        "First we are going to use a FC network with several layers and RELU as an activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNLXH6GrmlpJ"
      },
      "source": [
        "\"\"\" We define a network with 3 layers each one with N/2 neurons \"\"\"\n",
        "\"\"\" We use a hot one vector for our t.\"\"\"\n",
        "\n",
        "class FCNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_shape):\n",
        "        super(FCNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_shape, 128)\n",
        "        self.fc2 = nn.Linear(128,64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, start_dim = 1)\n",
        "        y = F.relu(self.fc1(x))\n",
        "        y = F.relu(self.fc2(y))\n",
        "        y = F.relu(self.fc3(y))\n",
        "        y = F.softmax(y)\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Hwi4d5rI_l"
      },
      "source": [
        "net = FCNet(784)\n",
        "\n",
        "mse = nn.MSELoss(reduction = 'none') # MSE\n",
        "\n",
        "# Btch SGD procedure\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.003, momentum = 0.9)\n",
        "start_time = time()\n",
        "number_of_epochs = 4\n",
        "for epoch in range(number_of_epochs):\n",
        "    current_loss = 0.0\n",
        "    for x, t in train_data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y = net(x)\n",
        "        t = F.one_hot(t)\n",
        "        loss = mse(y, t.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()\n",
        "    print(f\"epoch: {epoch} \\t loss: {current_loss/len(train)}\")\n",
        "\n",
        "end_time = time()\n",
        "ellapsed_time = end_time - start_time\n",
        "print(f\"Total time for {number_of_epochs+1} epochs: {ellapsed_time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fzqcymTrMuA"
      },
      "source": [
        "# Using gpu\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# net = FCNet(784)\n",
        "net = net.to(device)\n",
        "\n",
        "mse = nn.MSELoss(reduction='mean')\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.003, momentum = 0.9)\n",
        "start_time = time()\n",
        "\n",
        "number_of_epochs = 64\n",
        "for epoch in range(number_of_epochs):\n",
        "    current_loss = 0.0\n",
        "    for x, t in train_data_loader:\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y = net(x)\n",
        "        t = F.one_hot(t)\n",
        "        loss = mse(y, t.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        current_loss += loss.item()\n",
        "    print(f\"epoch: {epoch} \\t loss: {current_loss}\")\n",
        "\n",
        "end_time = time()\n",
        "ellapsed_time = end_time - start_time\n",
        "print(f\"Total time for {number_of_epochs+1} epochs: {ellapsed_time}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbFBfsRPx2Xz"
      },
      "source": [
        "# Model Evaluation\n",
        "\n",
        "Once the loss seems to be an acceptable value, there are several points to consider in this aspect, we make an evaluation.\n",
        "\n",
        "## Accuracy\n",
        "\n",
        "One of the simplest ways to evaluate our model is the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmST0zUSx1sP"
      },
      "source": [
        "corrects = 0\n",
        "for x,t in val_data_loader:\n",
        "    x = x.to(device)\n",
        "    t = t.to(device)\n",
        "    with torch.no_grad():\n",
        "        y = net(x)\n",
        "        prob, predicted = torch.max(y, 1)\n",
        "        corrects += (predicted == t).sum()\n",
        "\n",
        "print(f\"Total corrects {corrects} of {len(val)}, acc = {corrects/len(val)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUrrT2VwxU-q"
      },
      "source": [
        "# Saving the model for latter\n",
        "net = net.to(torch.device('cpu'))\n",
        "torch.save(net, 'fcmodel_trained.mdl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9tF3G4v7ryZ"
      },
      "source": [
        "# You can upload a trained model.\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = file.upload()\n",
        "\n",
        "# To reload the model\n",
        "\n",
        "net2 = torch.load('fcmodel_trained.mdl')\n",
        "\n",
        "corrects = 0\n",
        "for x,t in val_data_loader:\n",
        "    x = x.to(device)\n",
        "    t = t.to(device)\n",
        "    with torch.no_grad():\n",
        "        y = net(x)\n",
        "        prob, predicted = torch.max(y, 1)\n",
        "        corrects += (predicted == t).sum()\n",
        "\n",
        "print(f\"Total corrects {corrects} of {len(val)}, acc = {corrects/len(val)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJYhXEgUAGWq"
      },
      "source": [
        "# Readings\n",
        "\n",
        "- The first great breakthrugh or CNN [AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf).\n",
        "- A more efficient algorithm to train neural networks [Adam](https://arxiv.org/abs/1412.6980).\n",
        "- A breakthrugh on cnn architectures [ResNet](https://arxiv.org/abs/1512.03385)."
      ]
    }
  ]
}